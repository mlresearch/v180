---
title: Learning functions on multiple sets using multi-set transformers
abstract: We propose a general deep architecture for learning functions on multiple
  permutation-invariant sets.  We also show how to generalize this architecture to
  sets of elements of any dimension by dimension equivariance. We demonstrate that
  our architecture is a universal approximator of these functions, and show superior
  results to existing methods on a variety of tasks including counting tasks, alignment
  tasks, distinguishability tasks and statistical distance measurements. This last
  task is quite important in Machine Learning.  Although our approach is quite general,
  we demonstrate that it can generate approximate estimates of KL divergence and mutual
  information that are more accurate than previous techniques that are specifically
  designed to approximate those statistical distances.
openreview: HzMEEOUs5x5
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: selby22a
month: 0
tex_title: Learning functions on multiple sets using multi-set transformers
firstpage: 1760
lastpage: 1770
page: 1760-1770
order: 1760
cycles: false
bibtex_author: Selby, Kira A. and Rashid, Ahmad and Kobyzev, Ivan and Rezagholizadeh,
  Mehdi and Poupart, Pascal
author:
- given: Kira A.
  family: Selby
- given: Ahmad
  family: Rashid
- given: Ivan
  family: Kobyzev
- given: Mehdi
  family: Rezagholizadeh
- given: Pascal
  family: Poupart
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/selby22a/selby22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v180/selby22a/selby22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
