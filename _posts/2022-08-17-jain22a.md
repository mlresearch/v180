---
title: Towards painless policy optimization for constrained MDPs
abstract: We study policy optimization in an infinite horizon, $\gamma$-discounted
  constrained Markov decision process (CMDP). Our objective is to return a policy
  that achieves large expected reward with a small constraint violation. We consider
  the online setting with linear function approximation and assume global access to
  the corresponding features. We propose a generic primal-dual framework that allows
  us to bound the reward sub-optimality and constraint violation for arbitrary algorithms
  in terms of their primal and dual regret on online linear optimization problems.
  We instantiate this framework to use coin-betting algorithms and propose the \textbf{Coin
  Betting Politex (CBP)} algorithm. Assuming that the action-value functions are $\epsilon_{\text{\tiny{b}}}$-close
  to the span of the $d$-dimensional state-action features and no sampling errors,
  we prove that $T$ iterations of CBP result in an $O\left(\frac{1}{(1 - \gamma)^3
  \sqrt{T}} + \frac{\epsilon_{\text{\tiny{b}}} \sqrt{d}}{(1 - \gamma)^2} \right)$
  reward sub-optimality and an $O\left(\frac{1}{(1 - \gamma)^2 \sqrt{T}} + \frac{\epsilon_{\text{\tiny{b}}}
  \sqrt{d}}{1 - \gamma} \right)$ constraint violation. Importantly, unlike gradient
  descent-ascent and other recent methods, CBP does not require extensive hyperparameter
  tuning. Via experiments on synthetic and Cartpole environments, we demonstrate the
  effectiveness and robustness of CBP.
openreview: HgWfewLsqxc
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jain22a
month: 0
tex_title: Towards painless policy optimization for constrained {MDP}s
firstpage: 895
lastpage: 905
page: 895-905
order: 895
cycles: false
bibtex_author: Jain, Arushi and Vaswani, Sharan and Babanezhad, Reza and Szepesv\'ari,
  Csaba and Precup, Doina
author:
- given: Arushi
  family: Jain
- given: Sharan
  family: Vaswani
- given: Reza
  family: Babanezhad
- given: Csaba
  family: Szepesv√°ri
- given: Doina
  family: Precup
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/jain22a/jain22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v180/jain22a/jain22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
