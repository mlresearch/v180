---
title: Asymptotic optimality for active learning processes
abstract: Active Learning (AL) aims to optimize basic learned model(s) iteratively
  by selecting and annotating unlabeled data samples that are deemed to best maximise
  the model performance with minimal required data. However, the learned model is
  easy to overfit due to the biased distribution (sampling bias and dataset shift)
  formed by non-uniform sampling used in AL. Considering AL as an iterative sequential
  optimization process, we first provide a perspective on AL in terms of statistical
  properties, i.e., asymptotic unbiasedness, consistency and asymptotic efficiency,
  with respect to basic estimators when the sample size (size of labeled set) becomes
  large, and in the limit as sample size tends to infinity. We then discuss how biases
  affect AL. Finally, we proposed a flexible AL framework that aims to mitigate the
  impact of bias in AL by minimizing generalization error and importance-weighted
  training loss simultaneously.
openreview: HluKULi5xq
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhan22a
month: 0
tex_title: Asymptotic optimality for active learning processes
firstpage: 2342
lastpage: 2352
page: 2342-2352
order: 2342
cycles: false
bibtex_author: Zhan, Xueying and Wang, Yaowei and Chan, Antoni~B.
author:
- given: Xueying
  family: Zhan
- given: Yaowei
  family: Wang
- given: AntoniÂ B.
  family: Chan
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/zhan22a/zhan22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v180/zhan22a/zhan22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
