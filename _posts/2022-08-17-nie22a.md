---
title: An explore-then-commit algorithm for submodular maximization under full-bandit
  feedback
abstract: We investigate the problem of combinatorial multi-armed bandits with stochastic
  submodular (in expectation) rewards and full-bandit feedback, where no extra information
  other than the reward of selected action at each time step $t$ is observed. We propose
  a simple algorithm, Explore-Then-Commit Greedy (ETCG) and prove that it achieves
  a $(1-1/e)$-regret upper bound of $\mathcal{O}(n^\frac{1}{3}k^\frac{4}{3}T^\frac{2}{3}\log(T)^\frac{1}{2})$
  for a horizon $T$, number of base elements $n$, and cardinality constraint $k$.
  We also show in experiments with synthetic and real-world data that the ETCG empirically
  outperforms other full-bandit methods.
openreview: Hg-IBdIo5e9
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nie22a
month: 0
tex_title: An explore-then-commit algorithm for submodular maximization under full-bandit
  feedback
firstpage: 1541
lastpage: 1551
page: 1541-1551
order: 1541
cycles: false
bibtex_author: Nie, Guanyu and Agarwal, Mridul and Umrawal, Abhishek Kumar and Aggarwal,
  Vaneet and John Quinn, Christopher
author:
- given: Guanyu
  family: Nie
- given: Mridul
  family: Agarwal
- given: Abhishek Kumar
  family: Umrawal
- given: Vaneet
  family: Aggarwal
- given: Christopher
  family: John Quinn
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/nie22a/nie22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v180/nie22a/nie22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
