---
title: Cyclic test time augmentation with entropy weight method
abstract: In the recent studies of data augmentation of neural networks, the application
  of test time augmentation has been studied to extract optimal transformation policies
  to enhance performance with minimum cost. The policy search method with the best
  level of input data dependency involves training a loss predictor network to estimate
  suitable transformations for each of the given input image in independent manner,
  resulting in instance-level transformation extraction. In this work, we propose
  a method to utilize and modify the loss prediction pipeline to further improve the
  performance with the cyclic search for suitable transformations and the use of the
  entropy weight method. The cyclic usage of the loss predictor allows refining each
  input image with multiple transformations with a more flexible transformation magnitude.
  For cases where multiple augmentations are generated, we implement the entropy weight
  method to reflect the data uncertainty of each augmentation to force the final result
  to focus on augmentations with low uncertainty. The experimental results show convincing
  qualitative outcomes and robust performance for the corrupted conditions of data.
openreview: rKZlJUIj5lc
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chun22a
month: 0
tex_title: Cyclic test time augmentation with entropy weight method
firstpage: 433
lastpage: 442
page: 433-442
order: 433
cycles: false
bibtex_author: Chun, Sewhan and Lee, Jae Young and Kim, Junmo
author:
- given: Sewhan
  family: Chun
- given: Jae Young
  family: Lee
- given: Junmo
  family: Kim
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/chun22a/chun22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v180/chun22a/chun22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
