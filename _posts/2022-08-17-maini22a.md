---
title: Perturbation type categorization for multiple adversarial perturbation robustness
abstract: Recent works in adversarial robustness have proposed defenses to improve
  the robustness of a single model against the union of multiple perturbation types.
  However, these methods still suffer significant trade-offs compared to the ones
  specifically trained to be robust against a single perturbation type. In this work,
  we introduce the problem of categorizing adversarial examples based on their perturbation
  types. We first theoretically show on a toy task that adversarial examples of different
  perturbation types constitute different distributionsâ€”making it possible to distinguish
  them. We support these arguments with experimental validation on multiple l_p attacks
  and common corruptions. Instead of training a single classifier, we propose PROTECTOR,
  a two-stage pipeline that first categorizes the perturbation type of the input,
  and then makes the final prediction using the classifier specifically trained against
  the predicted perturbation type. We theoretically show that at test time the adversary
  faces a natural trade-off between fooling the perturbation classifier and the succeeding
  classifier optimized with perturbation-specific adversarial training. This makes
  it challenging for an adversary to plant strong attacks against the whole pipeline.
  Experiments on MNIST and CIFAR-10 show that PROTECTOR outperforms prior adversarial
  training-based defenses by over 5% when tested against the union of l_1, l_2, l_inf
  attacks. Additionally, our method extends to a more diverse attack suite, also showing
  large robustness gains against multiple l_p, spatial and recolor attacks.
openreview: BlbhyDUo9xc
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: maini22a
month: 0
tex_title: Perturbation type categorization for multiple adversarial perturbation
  robustness
firstpage: 1317
lastpage: 1327
page: 1317-1327
order: 1317
cycles: false
bibtex_author: Maini, Pratyush and Chen, Xinyun and Li, Bo and Song, Dawn
author:
- given: Pratyush
  family: Maini
- given: Xinyun
  family: Chen
- given: Bo
  family: Li
- given: Dawn
  family: Song
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/maini22a/maini22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v180/maini22a/maini22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
