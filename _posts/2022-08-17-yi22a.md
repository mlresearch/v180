---
title: 'Accelerating training of batch normalization: A manifold perspective'
abstract: Batch normalization (BN) has become a critical component across diverse
  deep neural networks. The network with BN is invariant to positively linear re-scale
  transformation, which makes there exist infinite functionally equivalent networks
  with different scales of weights. However, optimizing these equivalent networks
  with the first-order method such as stochastic gradient descent will obtain a series
  of iterates converging to different local optima owing to their different gradients
  across training. To obviate this, we propose a quotient manifold PSI manifold, in
  which all the equivalent weights of the network with BN are regarded as the same
  element. Next, we construct gradient descent and stochastic gradient descent on
  the proposed PSI manifold to train the network with BN. The two algorithms guarantee
  that every group of equivalent weights (caused by positively re-scaling) converge
  to the equivalent optima. Besides that, we give convergence rates of the proposed
  algorithms on the PSI manifold. The results show that our methods accelerate training
  compared with the algorithms on the Euclidean weight space. Finally, empirical results
  verify that our algorithms consistently improve the existing methods in both convergence
  rate and generalization ability under various experimental settings.
openreview: BYUfYU8oce9
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yi22a
month: 0
tex_title: 'Accelerating training of batch normalization: A manifold perspective'
firstpage: 1128
lastpage: 1137
page: 1128-1137
order: 1128
cycles: false
bibtex_author: Yi, Mingyang
author:
- given: Mingyang
  family: Yi
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/yi22a/yi22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v180/yi22a/yi22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
