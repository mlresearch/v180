---
title: Robust expected information gain for optimal Bayesian experimental design using
  ambiguity sets
abstract: The ranking of experiments by expected information gain (EIG) in Bayesian
  experimental design is sensitive to changes in the modelâ€™s prior distribution, and
  the approximation of EIG yielded by sampling will have errors similar to the use
  of a perturbed prior. We define and analyze Robust Expected Information Gain(REIG),
  a modification of the objective in EIG maximization by minimizing an affine relaxation
  of EIG over an ambiguity set of distributions that are close to the original prior
  in KL-divergence. We show that, when combined with a sampling-based approach to
  estimating EIG, REIG corresponds to a "log-sum-exp" stabilization of the samples
  used to estimate EIG, meaning that it can be efficiently implemented in practice.
  Numerical tests combining REIG with variational nested Monte Carlo (VNMC), adaptive
  contrastive estimation (ACE) and mutual information neural estimation (MINE) suggest
  that in practice REIG also compensates for the variability of under-sampled estimators.
openreview: HU9IxO8oqlc
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: go22a
month: 0
tex_title: Robust expected information gain for optimal Bayesian experimental design
  using ambiguity sets
firstpage: 728
lastpage: 737
page: 728-737
order: 728
cycles: false
bibtex_author: Go, Jinwoo and Isaac, Tobin
author:
- given: Jinwoo
  family: Go
- given: Tobin
  family: Isaac
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/go22a/go22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
