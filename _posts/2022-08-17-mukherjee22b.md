---
title: 'ReVar: Strengthening policy evaluation via reduced variance sampling'
abstract: This paper studies the problem of data collection for policy evaluation
  in Markov decision processes (MDPs). In policy evaluation, we are given a \textit{target}
  policy and asked to estimate the expected cumulative reward it will obtain in an
  environment formalized as an MDP. We develop theory for optimal data collection
  within the class of tree-structured MDPs by first deriving an oracle exploration
  strategy that uses knowledge of  the variance of the reward distributions. We then
  introduce the \textbf{Re}duced \textbf{Var}iance Sampling (\rev\!) algorithm that
  approximates the oracle strategy when the reward variances are unknown a priori
  and bound its sub-optimality compared to the oracle strategy. Finally, we empirically
  validate that \rev leads to policy evaluation with mean squared error comparable
  to the oracle strategy and significantly lower than simply running the target policy.
openreview: B5Lf6PUoqg5
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mukherjee22b
month: 0
tex_title: 'ReVar: Strengthening policy evaluation via reduced variance sampling'
firstpage: 1413
lastpage: 1422
page: 1413-1422
order: 1413
cycles: false
bibtex_author: Mukherjee, Subhojyoti and Hanna, Josiah P. and Nowak, Robert D
author:
- given: Subhojyoti
  family: Mukherjee
- given: Josiah P.
  family: Hanna
- given: Robert D
  family: Nowak
date: 2022-08-17
address:
container-title: Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial
  Intelligence
volume: '180'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 8
  - 17
pdf: https://proceedings.mlr.press/v180/mukherjee22b/mukherjee22b.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v180/mukherjee22b/mukherjee22b-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
